{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Sentiment Analysis using News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=pd.read_csv('bangla_sms_data.txt', sep='\\t', names=[\"label\", \"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>জুরং পয়েন্ট অবধি পাগল হওয়া, ক্রেজি .. কেবল ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ঠিক আছে লার ... আপনি যদি ওনিকে ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>1 21 মে 2005 এফএ কাপ ফাইনালের টিকিট জিতে 2 উইক...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>ইউ দুন এত তাড়াতাড়ি বলে ... ইউ সি ইতিমধ্যে ত...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>নাহ, আমি মনে করি না তিনি ইউএসএফের কাছে যান, য...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           messages\n",
       "0   ham   জুরং পয়েন্ট অবধি পাগল হওয়া, ক্রেজি .. কেবল ...\n",
       "1   ham                 ঠিক আছে লার ... আপনি যদি ওনিকে ...\n",
       "2  spam  1 21 মে 2005 এফএ কাপ ফাইনালের টিকিট জিতে 2 উইক...\n",
       "3   ham   ইউ দুন এত তাড়াতাড়ি বলে ... ইউ সি ইতিমধ্যে ত...\n",
       "4   ham   নাহ, আমি মনে করি না তিনি ইউএসএফের কাছে যান, য..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahadhasan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/Users/fahadhasan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/Users/fahadhasan/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished preprocessing\n",
      "(1953, 1087)\n",
      "(1953,)\n",
      "[0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from bltk.langtools import remove_stopwords\n",
    "from bltk.langtools import Tokenizer\n",
    "from bltk.langtools import UgraStemmer\n",
    "import re\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "stemmer = UgraStemmer()\n",
    "\n",
    "\n",
    "corpus = []\n",
    "y_val = []\n",
    "for i in range(0, len(messages)):\n",
    "    review = messages['messages'][i]\n",
    "    y_val_temp = messages['label'][i]\n",
    "    review = \"\".join(i for i in review if i in [\"।\"] or 2432 <= ord(i) <= 2559 or ord(i)== 32)\n",
    "    review =\" \".join(review.split())\n",
    "    \n",
    "    review = tokenizer.word_tokenizer(review)\n",
    "    #print(review)\n",
    "    while(\"\" in review) : \n",
    "        review.remove(\"\") \n",
    "    review = remove_stopwords(review, level='hard')\n",
    "    #print(review)\n",
    "    review = stemmer.stem(review)\n",
    "    #print(review)\n",
    "    if(review==None):\n",
    "        continue\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    corpus.append(review)\n",
    "    y_val.append(y_val_temp)\n",
    "    \n",
    "\n",
    "\n",
    "print(\"finished preprocessing\")\n",
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1800)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "y=pd.get_dummies(y_val)#(messages['label'])\n",
    "y = y.iloc[:,1].values\n",
    "\n",
    "#X = X.reshape(X.shape[1:])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y)\n",
    "\n",
    "# Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "# Training model using Naive bayes classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=spam_detect_model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import library to check accuracy\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[323  15]\n",
      " [ 17  36]]\n",
      "0.9181585677749361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       338\n",
      "           1       0.71      0.68      0.69        53\n",
      "\n",
      "    accuracy                           0.92       391\n",
      "   macro avg       0.83      0.82      0.82       391\n",
      "weighted avg       0.92      0.92      0.92       391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix=confusion_matrix(y_test,y_pred)\n",
    "print(matrix)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(score)\n",
    "report=classification_report(y_test,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
